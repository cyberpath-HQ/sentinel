---
title: Migration Guide
description: Guide for migrating from traditional databases to Sentinel and upgrading between Sentinel versions.
section: Advanced Topics
order: 31
keywords: ["migration", "upgrade", "database", "transition", "compatibility"]
related: ["architecture", "examples", "quick-start"]
---

This guide helps you migrate to Sentinel from traditional databases and upgrade between Sentinel versions.

## Migrating to Sentinel

### When to Choose Sentinel

Sentinel is ideal when you need:

- **Auditability**: Every change must be traceable
- **Compliance**: GDPR, SOC 2, HIPAA, ISO 27001 requirements
- **Transparency**: Human-readable data that anyone can inspect
- **Simplicity**: No database server to manage
- **Git Integration**: Version control for your data
- **Filesystem Tools**: Use standard Unix tools for data operations

### When NOT to Choose Sentinel

Consider alternatives if you need:

- High-frequency writes (>10,000 ops/sec)
- Complex joins across multiple collections
- Real-time analytics
- Sub-millisecond latency
- Distributed transactions

## From PostgreSQL

### Data Export

Export your PostgreSQL data to JSON:

```sql
-- Export table to JSON
COPY (
    SELECT json_agg(row_to_json(t))
    FROM users t
) TO '/tmp/users.json';
```

### Import to Sentinel

```rust
use sentinel_dbms::Store;
use serde_json::Value;
use std::fs;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let store = Store::new("./sentinel_db", None).await?;
    let users = store.collection("users").await?;

    // Read exported JSON
    let json_data = fs::read_to_string("/tmp/users.json")?;
    let records: Vec<Value> = serde_json::from_str(&json_data)?;

    // Insert each record
    for record in records {
        let id = record["id"].as_str().unwrap();
        users.insert(id, record).await?;
    }

    println!("Migrated {} records", records.len());
    Ok(())
}
```

### Schema Differences

| PostgreSQL   | Sentinel               | Notes               |
| ------------ | ---------------------- | ------------------- |
| Tables       | Collections            | Directory-based     |
| Rows         | Documents              | JSON files          |
| Primary Key  | Document ID            | Filename            |
| Foreign Keys | Manual references      | Store related IDs   |
| Indexes      | Query filters          | In-memory filtering |
| Transactions | Atomic file operations | Single-document     |

### Query Translation

**PostgreSQL:**

```sql
SELECT name, email FROM users
WHERE age > 25 AND role = 'admin'
ORDER BY name ASC
LIMIT 10;
```

**Sentinel:**

```rust
use sentinel_dbms::{QueryBuilder, Operator, SortOrder};
use serde_json::json;

let query = QueryBuilder::new()
    .filter("age", Operator::GreaterThan, json!(25))
    .filter("role", Operator::Equals, json!("admin"))
    .sort("name", SortOrder::Ascending)
    .limit(10)
    .project(vec!["name".to_string(), "email".to_string()])
    .build();

let result = users.query(query).await?;
```

## From MongoDB

### Data Export

Export MongoDB collection to JSON:

```bash
mongoexport --db mydb --collection users --out users.json --jsonArray
```

### Import to Sentinel

```rust
use sentinel_dbms::Store;
use serde_json::Value;
use std::fs;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let store = Store::new("./sentinel_db", None).await?;
    let users = store.collection("users").await?;

    let json_data = fs::read_to_string("users.json")?;
    let records: Vec<Value> = serde_json::from_str(&json_data)?;

    for record in records {
        // MongoDB uses _id, Sentinel uses id
        let id = record["_id"]["$oid"]
            .as_str()
            .unwrap_or_else(|| record["_id"].as_str().unwrap());

        users.insert(id, record).await?;
    }

    println!("Migration complete");
    Ok(())
}
```

### Query Translation

**MongoDB:**

```javascript
db.users
  .find({
    age: { $gt: 25 },
    role: "admin",
  })
  .sort({ name: 1 })
  .limit(10);
```

**Sentinel:**

```rust
use sentinel_dbms::{QueryBuilder, Operator, SortOrder};
use serde_json::json;

let query = QueryBuilder::new()
    .filter("age", Operator::GreaterThan, json!(25))
    .filter("role", Operator::Equals, json!("admin"))
    .sort("name", SortOrder::Ascending)
    .limit(10)
    .build();
```

## From SQLite

### Data Export

```bash
sqlite3 mydb.db <<EOF
.mode json
.output users.json
SELECT * FROM users;
.quit
EOF
```

### Import to Sentinel

```rust
use sentinel_dbms::Store;
use serde_json::Value;
use std::fs;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let store = Store::new("./sentinel_db", None).await?;
    let users = store.collection("users").await?;

    let json_data = fs::read_to_string("users.json")?;
    let records: Vec<Value> = serde_json::from_str(&json_data)?;

    for record in records {
        let id = record["id"].as_str()
            .map(|s| s.to_string())
            .or_else(|| record["id"].as_i64().map(|n| n.to_string()))
            .unwrap();

        users.insert(&id, record).await?;
    }

    Ok(())
}
```

## From JSON Files

If you already have JSON files, Sentinel can work with them directly:

```rust
use sentinel_dbms::Store;
use serde_json::Value;
use std::fs;
use walkdir::WalkDir;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let store = Store::new("./sentinel_db", None).await?;
    let data_collection = store.collection("imported_data").await?;

    // Walk through existing JSON files
    for entry in WalkDir::new("./existing_json_files") {
        let entry = entry?;
        if entry.path().extension().and_then(|s| s.to_str()) == Some("json") {
            let content = fs::read_to_string(entry.path())?;
            let data: Value = serde_json::from_str(&content)?;

            // Use filename as document ID
            let id = entry.path().file_stem()
                .and_then(|s| s.to_str())
                .unwrap();

            data_collection.insert(id, data).await?;
        }
    }

    Ok(())
}
```

## Handling Relationships

### One-to-Many

**Traditional Database:**

```sql
-- Users table
CREATE TABLE users (id, name, email);

-- Posts table with foreign key
CREATE TABLE posts (id, user_id, title, content);
```

**Sentinel Approach:**

```rust
// Store user reference in each post
users.insert("user-1", json!({
    "name": "Alice",
    "email": "alice@example.com"
})).await?;

posts.insert("post-1", json!({
    "user_id": "user-1",  // Reference
    "title": "My First Post",
    "content": "Hello world"
})).await?;

// Query posts by user
let user_posts = posts.filter(|doc| {
    doc.data()["user_id"].as_str() == Some("user-1")
});
```

### Many-to-Many

**Sentinel Approach:**

```rust
// Store array of references
users.insert("user-1", json!({
    "name": "Alice",
    "group_ids": ["group-1", "group-2"]
})).await?;

groups.insert("group-1", json!({
    "name": "Admins",
    "user_ids": ["user-1", "user-2"]
})).await?;
```

## Performance Considerations

### Indexing Strategy

Traditional databases have automatic indices. In Sentinel:

1. **Use Descriptive IDs**: Make document IDs meaningful for direct access
2. **Denormalize Data**: Include frequently accessed data in documents
3. **Filter Early**: Apply most selective filters first
4. **Limit Results**: Use `.limit()` to reduce processing

### Caching Pattern

```rust
use std::collections::HashMap;
use std::sync::{Arc, Mutex};

struct CachedStore {
    store: Store,
    cache: Arc<Mutex<HashMap<String, serde_json::Value>>>,
}

impl CachedStore {
    async fn get_cached(&self, collection: &str, id: &str) -> Result<Option<Value>> {
        let cache_key = format!("{}:{}", collection, id);

        // Check cache
        if let Some(cached) = self.cache.lock().unwrap().get(&cache_key) {
            return Ok(Some(cached.clone()));
        }

        // Load from store
        let coll = self.store.collection(collection).await?;
        if let Some(doc) = coll.get(id).await? {
            let data = doc.data().clone();
            self.cache.lock().unwrap().insert(cache_key, data.clone());
            Ok(Some(data))
        } else {
            Ok(None)
        }
    }
}
```

## Migration Checklist

- [ ] Export data from source database
- [ ] Validate JSON structure
- [ ] Test migration on sample data
- [ ] Backup existing Sentinel store (if upgrading)
- [ ] Run full migration
- [ ] Verify data integrity
- [ ] Test application functionality
- [ ] Update application code
- [ ] Monitor performance
- [ ] Keep backup for rollback period

## Getting Help

If you encounter issues during migration:

1. Check [GitHub Discussions](https://github.com/cyberpath-HQ/sentinel/discussions)
2. Open an [Issue](https://github.com/cyberpath-HQ/sentinel/issues)
3. Review [Examples](/docs/examples) for patterns
4. Read [Architecture](/docs/architecture) for understanding internals

## Next Steps

- Review [Examples](/docs/examples) for common patterns
- Learn about [Querying](/docs/querying) for data access
- Understand [Architecture](/docs/architecture) for performance tuning
- Explore [API Reference](/docs/api-reference) for complete API
